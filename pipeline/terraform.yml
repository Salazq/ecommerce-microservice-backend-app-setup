# Este pipeline se debe disparar manualmente.
trigger: none

pool:
  vmImage: ubuntu-latest

parameters:
- name: environment
  displayName: 'Select Environment'
  type: string
  default: 'dev'
  values:
  - dev
  - staging
  - prod

variables:
  - group: variable-group-taller
  - name: environmentPath
    value: 'terraform/environments/${{ parameters.environment }}'
  - name: aksResourceGroup
    value: '${{ parameters.environment }}-resource-group'
  - name: aksClusterName
    value: '${{ parameters.environment }}-aks-cluster'
  - name: kubernetesNamespace
    value: 'logging'


stages:
- stage: Terraform_plan_apply_${{ parameters.environment }}
  displayName: 'Terraform Plan & Apply - ${{ parameters.environment }}'
  # Etapa √∫nica: Generar el plan y aplicar Terraform.
  jobs:
    - job: PlanAndApply
      continueOnError: false
      timeoutInMinutes: 30
      steps:
        # Paso 1: Instalar Terraform
        - task: TerraformInstaller@0
          inputs:
            terraformVersion: '1.5.7'
          displayName: 'Install Terraform'

        # Paso 2: Verificar versi√≥n
        - script: terraform --version
          displayName: 'Check Terraform version'        
          # Paso 3: Verificar estructura de directorios
        - script: |
            echo "Working with environment: ${{ parameters.environment }}"
            echo "Environment path: $(environmentPath)"
            echo "Current directory: $(System.DefaultWorkingDirectory)"
            ls -la $(System.DefaultWorkingDirectory)/ || dir $(System.DefaultWorkingDirectory)\
            ls -la $(System.DefaultWorkingDirectory)/$(environmentPath)/ || dir $(System.DefaultWorkingDirectory)\$(environmentPath)\ || echo "Directory not found"
            echo "Files in environment directory:"
            ls -la $(System.DefaultWorkingDirectory)/$(environmentPath)/*.tf $(System.DefaultWorkingDirectory)/$(environmentPath)/*.tfvars 2>/dev/null || dir $(System.DefaultWorkingDirectory)\$(environmentPath)\*.tf $(System.DefaultWorkingDirectory)\$(environmentPath)\*.tfvars 2>nul || echo "No .tf or .tfvars files found"
          displayName: 'Check directory structure and files'
        # Paso 4: Terraform init
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'init'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            backendServiceArm: $(AZURE_ACCOUNT)
            backendAzureRmResourceGroupName: 'VM'
            backendAzureRmStorageAccountName: 'vmrecursos'
            backendAzureRmContainerName: 'tfstate'
            backendAzureRmKey: '${{ parameters.environment }}-aks.tfstate'
          displayName: 'Terraform init'

        # Paso 5: Terraform validate
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'validate'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
          displayName: 'Terraform validate'        # Paso 6: Terraform plan (usando task oficial)
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'plan'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            environmentServiceNameAzureRM: $(AZURE_ACCOUNT)
            commandOptions: '-out=plan.out -var-file=terraform.tfvars'
          displayName: 'Terraform Plan'

        # Paso 7: Publicar artefacto del plan
        - task: PublishPipelineArtifact@1
          inputs:
            targetPath: '$(System.DefaultWorkingDirectory)/$(environmentPath)/plan.out'
            artifact: 'Plan-${{ parameters.environment }}'
            publishLocation: 'pipeline'
          displayName: 'Publish Plan Artifact'
          condition: succeeded()

        # Paso 8: Terraform apply
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'apply'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            environmentServiceNameAzureRM: $(AZURE_ACCOUNT)
            commandOptions: '-auto-approve plan.out'
          displayName: 'Terraform Apply - ${{ parameters.environment }}'        # Paso 9: Mostrar outputs
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'output'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            environmentServiceNameAzureRM: $(AZURE_ACCOUNT)
          displayName: 'Show Terraform Outputs'
          continueOnError: true

        # Paso 10: Validar deployment
        - script: |
            echo "Deployment completed for environment: ${{ parameters.environment }}"
            echo "Validating deployment..."
            cd $(System.DefaultWorkingDirectory)/$(environmentPath)
            # Verificar estado de Terraform
            terraform show -json > terraform_state.json 2>/dev/null || echo "Could not export state"
            # Mostrar resumen de recursos creados
            terraform state list 2>/dev/null || echo "Could not list state"
            echo "Deployment validation completed"
          displayName: 'Validate Deployment'
          continueOnError: true

        # Paso 11: Cleanup temporal files
        - script: |
            cd $(System.DefaultWorkingDirectory)/$(environmentPath)
            # Limpiar archivos temporales pero conservar el estado
            rm -f plan.out terraform_state.json 2>/dev/null || del plan.out terraform_state.json 2>nul
            echo "Cleanup completed"
          displayName: 'Cleanup temporary files'
          continueOnError: true
          condition: always()

- stage: DeployMonitoringStack
  displayName: 'Instalar Prometheus & Grafana con Helm'
  dependsOn: Terraform_plan_apply_${{ parameters.environment }}
  condition: succeeded()
  jobs:
    - job: InstallMonitoring
      displayName: 'Helm Install kube-prometheus-stack'
      pool:
        vmImage: 'ubuntu-latest'
      steps:
        - task: HelmInstaller@1
          inputs:
            helmVersionToInstall: '3.13.3'
        - task: AzureCLI@2
          displayName: 'Login en AKS'
          inputs:
            azureSubscription:  $(AZURE_ACCOUNT)  # Debe estar configurado en Azure DevOps
            scriptType: 'bash'
            scriptLocation: 'inlineScript'
            inlineScript: |
              az aks get-credentials --resource-group $(aksResourceGroup) --name $(aksClusterName) --overwrite-existing

        - script: |
            echo "üîß Crear namespace monitoring si no existe"
            kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

            echo "üì¶ Agregar repositorio Helm de Prometheus"
            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
            helm repo update

            echo "üöÄ Instalar kube-prometheus-stack con configuraci√≥n para Nginx"
            helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
              --namespace monitoring \
              --set grafana.adminPassword='MiPassword123' \
              --set grafana.service.type=ClusterIP \
              --set grafana.env.GF_SERVER_ROOT_URL='http://localhost/grafana/' \
              --set prometheus.service.type=ClusterIP \
              --set prometheus.prometheusSpec.externalUrl='http://localhost/prometheus/'\
              --set prometheus.prometheusSpec.routePrefix='/prometheus'
          displayName: 'Instalar Prometheus y Grafana en monitoring'


- stage: InstallELKStack
  displayName: 'Instalar ELK Stack completo en un solo stage'
  jobs:
    - job: DeployELK
      displayName: 'Deploy Elasticsearch, Kibana y Fluent Bit'
      pool:
        vmImage: 'ubuntu-latest'
      steps:
        - task: AzureCLI@2
          displayName: 'Autenticarse en Azure y desplegar ELK'
          inputs:
            azureSubscription:  $(AZURE_ACCOUNT)
            scriptType: bash
            scriptLocation: inlineScript
            inlineScript: |
              echo "üîê Autenticando en Azure y configurando AKS..."
              az aks get-credentials --resource-group $(aksResourceGroup) --name $(aksClusterName) --overwrite-existing

              echo "üîß A√±adiendo repositorios Helm..."
              helm repo add elastic https://helm.elastic.co || true
              helm repo add fluent https://fluent.github.io/helm-charts || true
              helm repo update

              echo "üßπ Eliminando posibles instalaciones previas..."
              helm uninstall elasticsearch -n $(kubernetesNamespace) || true
              helm uninstall kibana -n $(kubernetesNamespace) || true
              helm uninstall fluent-bit -n $(kubernetesNamespace) || true

              echo "üöÄ Creando namespace si no existe..."
              kubectl create namespace $(kubernetesNamespace) --dry-run=client -o yaml | kubectl apply -f -

              echo "üì¶ Instalando Elasticsearch..."
              helm upgrade --install elasticsearch elastic/elasticsearch \
                --namespace $(kubernetesNamespace) \
                --set replicas=1 \
                --set minimumMasterNodes=1 \
                --set resources.requests.cpu="100m" \
                --set resources.requests.memory="512Mi" \
                --set resources.limits.cpu="500m" \
                --set resources.limits.memory="1Gi" \
                --wait

              echo "üìä Instalando Kibana..."
              helm upgrade --install kibana elastic/kibana \
                --namespace $(kubernetesNamespace) \
                --set service.type=ClusterIP \
                --wait

              echo "üî• Instalando Fluent Bit..."
              helm upgrade --install fluent-bit fluent/fluent-bit \
                --namespace $(kubernetesNamespace) \
                --set backend.type=es \
                --set backend.es.host=elasticsearch-master \
                --set backend.es.port=9200 \
                --wait

              echo "‚úÖ ELK Stack instalado correctamente en el namespace '$(kubernetesNamespace)'"
