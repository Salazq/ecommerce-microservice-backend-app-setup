# Este pipeline se debe disparar manualmente.
trigger: none

pool:
  vmImage: ubuntu-latest

parameters:
- name: environment
  displayName: 'Select Environment'
  type: string
  default: 'dev'
  values:
  - dev
  - staging
  - prod

variables:
  - group: variable-group-taller
  - name: environmentPath
    value: 'terraform/environments/${{ parameters.environment }}'
  - name: aksResourceGroup
    value: '${{ parameters.environment }}-resource-group'
  - name: aksClusterName
    value: '${{ parameters.environment }}-aks-cluster'

stages:
- stage: Terraform_plan_apply_${{ parameters.environment }}
  displayName: 'Terraform Plan & Apply - ${{ parameters.environment }}'
  # Etapa 煤nica: Generar el plan y aplicar Terraform.
  jobs:
    - job: PlanAndApply
      continueOnError: false
      timeoutInMinutes: 30
      steps:
        # Paso 1: Instalar Terraform
        - task: TerraformInstaller@0
          inputs:
            terraformVersion: '1.5.7'
          displayName: 'Install Terraform'

        # Paso 2: Verificar versi贸n
        - script: terraform --version
          displayName: 'Check Terraform version'        
          # Paso 3: Verificar estructura de directorios
        - script: |
            echo "Working with environment: ${{ parameters.environment }}"
            echo "Environment path: $(environmentPath)"
            echo "Current directory: $(System.DefaultWorkingDirectory)"
            ls -la $(System.DefaultWorkingDirectory)/ || dir $(System.DefaultWorkingDirectory)\
            ls -la $(System.DefaultWorkingDirectory)/$(environmentPath)/ || dir $(System.DefaultWorkingDirectory)\$(environmentPath)\ || echo "Directory not found"
            echo "Files in environment directory:"
            ls -la $(System.DefaultWorkingDirectory)/$(environmentPath)/*.tf $(System.DefaultWorkingDirectory)/$(environmentPath)/*.tfvars 2>/dev/null || dir $(System.DefaultWorkingDirectory)\$(environmentPath)\*.tf $(System.DefaultWorkingDirectory)\$(environmentPath)\*.tfvars 2>nul || echo "No .tf or .tfvars files found"
          displayName: 'Check directory structure and files'
        # Paso 4: Terraform init
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'init'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            backendServiceArm: $(AZURE_ACCOUNT)
            backendAzureRmResourceGroupName: 'VM'
            backendAzureRmStorageAccountName: 'vmrecursos'
            backendAzureRmContainerName: 'tfstate'
            backendAzureRmKey: '${{ parameters.environment }}-aks.tfstate'
          displayName: 'Terraform init'

        # Paso 5: Terraform validate
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'validate'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
          displayName: 'Terraform validate'        # Paso 6: Terraform plan (usando task oficial)
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'plan'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            environmentServiceNameAzureRM: $(AZURE_ACCOUNT)
            commandOptions: '-out=plan.out -var-file=terraform.tfvars'
          displayName: 'Terraform Plan'

        # Paso 7: Publicar artefacto del plan
        - task: PublishPipelineArtifact@1
          inputs:
            targetPath: '$(System.DefaultWorkingDirectory)/$(environmentPath)/plan.out'
            artifact: 'Plan-${{ parameters.environment }}'
            publishLocation: 'pipeline'
          displayName: 'Publish Plan Artifact'
          condition: succeeded()

        # Paso 8: Terraform apply
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'apply'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            environmentServiceNameAzureRM: $(AZURE_ACCOUNT)
            commandOptions: '-auto-approve plan.out'
          displayName: 'Terraform Apply - ${{ parameters.environment }}'        # Paso 9: Mostrar outputs
        - task: TerraformTaskV4@4
          inputs:
            provider: 'azurerm'
            command: 'output'
            workingDirectory: '$(System.DefaultWorkingDirectory)/$(environmentPath)'
            environmentServiceNameAzureRM: $(AZURE_ACCOUNT)
          displayName: 'Show Terraform Outputs'
          continueOnError: true

        # Paso 10: Validar deployment
        - script: |
            echo "Deployment completed for environment: ${{ parameters.environment }}"
            echo "Validating deployment..."
            cd $(System.DefaultWorkingDirectory)/$(environmentPath)
            # Verificar estado de Terraform
            terraform show -json > terraform_state.json 2>/dev/null || echo "Could not export state"
            # Mostrar resumen de recursos creados
            terraform state list 2>/dev/null || echo "Could not list state"
            echo "Deployment validation completed"
          displayName: 'Validate Deployment'
          continueOnError: true

        # Paso 11: Cleanup temporal files
        - script: |
            cd $(System.DefaultWorkingDirectory)/$(environmentPath)
            # Limpiar archivos temporales pero conservar el estado
            rm -f plan.out terraform_state.json 2>/dev/null || del plan.out terraform_state.json 2>nul
            echo "Cleanup completed"
          displayName: 'Cleanup temporary files'
          continueOnError: true
          condition: always()

- stage: DeployMonitoringStack
  displayName: 'Instalar Prometheus & Grafana con Helm'
  dependsOn: Terraform_plan_apply_${{ parameters.environment }}
  condition: succeeded()
  jobs:
    - job: InstallMonitoring
      displayName: 'Helm Install kube-prometheus-stack'
      pool:
        vmImage: 'ubuntu-latest'
      steps:
        - task: HelmInstaller@1
          inputs:
            helmVersionToInstall: '3.13.3'
        - task: AzureCLI@2
          displayName: 'Login en AKS'
          inputs:
            azureSubscription:  $(AZURE_ACCOUNT)  # Debe estar configurado en Azure DevOps
            scriptType: 'bash'
            scriptLocation: 'inlineScript'
            inlineScript: |
              az aks get-credentials --resource-group $(aksResourceGroup) --name $(aksClusterName) --overwrite-existing

        - script: |
            echo " Crear namespace monitoring si no existe"
            kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

            echo " Agregar repositorio Helm de Prometheus"
            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
            helm repo update

            echo " Instalar kube-prometheus-stack con configuraci贸n para Nginx"
            helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
              --namespace monitoring \
              --set grafana.adminPassword='MiPassword123' \
              --set grafana.service.type=ClusterIP \
              --set grafana.env.GF_SERVER_ROOT_URL='http://localhost/grafana/' \
              --set prometheus.service.type=ClusterIP \
              --set prometheus.prometheusSpec.externalUrl='http://localhost/prometheus/'\
              --set prometheus.prometheusSpec.routePrefix='/prometheus'
          displayName: 'Instalar Prometheus y Grafana en monitoring'


- stage: DeployLoggingStackBasico
  displayName: 'Desplegar ELK Stack B谩sico'
  dependsOn: DeployMonitoringStack
  condition: succeeded()
  jobs:
    - job: InstallELKBasic
      displayName: 'Instalar Elasticsearch, Logstash y Kibana'
      pool:
        vmImage: 'ubuntu-latest'
      steps:
        - task: HelmInstaller@1
          inputs:
            helmVersionToInstall: '3.13.3'

        - task: AzureCLI@2
          displayName: 'Login en AKS'
          inputs:
            azureSubscription: $(AZURE_ACCOUNT)
            scriptType: bash
            scriptLocation: inlineScript
            inlineScript: |
              az aks get-credentials --resource-group $(aksResourceGroup) --name $(aksClusterName) --overwrite-existing

        - script: |
            echo "Ч Limpiando recursos anteriores..."
            kubectl delete ns logging --ignore-not-found
            kubectl create ns logging

            helm repo add elastic https://helm.elastic.co
            helm repo update
          displayName: 'Inicializar Namespace y Repositorios'

        - script: |
            echo " Instalando Elasticsearch (modo simple)..."
            helm install elasticsearch elastic/elasticsearch \
              --namespace logging \
              --set replicas=1 \
              --set minimumMasterNodes=1 \
              --set persistence.enabled=false \
              --set security.enabled=false \
              --set protocol=http \
              --set esJavaOpts="-Xms512m -Xmx512m" \
              --set extraEnvs[0].name=discovery.type \
              --set extraEnvs[0].value=single-node \
              --set extraEnvs[1].name=xpack.security.enabled \
              --set extraEnvs[1].value=false \
              --set extraEnvs[2].name=xpack.security.http.ssl.enabled \
              --set extraEnvs[2].value=false \
              --wait
          displayName: 'Instalar Elasticsearch'

        - script: |
            echo " Instalando Kibana..."
            helm install kibana elastic/kibana \
              --namespace logging \
              --set elasticsearchHosts=http://elasticsearch-master:9200 \
              --set elasticsearch.ssl.enabled=false \
              --set service.type=ClusterIP \
              --wait
          displayName: 'Instalar Kibana'

        - script: |
            echo " Creando ConfigMap de Logstash..."
            cat <<EOF | kubectl apply -f -
            apiVersion: v1
            kind: ConfigMap
            metadata:
              name: logstash-config
              namespace: logging
            data:
              logstash.conf: |
                input {
                  tcp {
                    port => 5000
                    codec => json
                  }
                }
                output {
                  elasticsearch {
                    hosts => ["http://elasticsearch-master:9200"]
                    index => "logstash-logs-%{+YYYY.MM.dd}"
                  }
                }
            EOF
          displayName: 'Crear ConfigMap de Logstash'

        - script: |
            echo " Instalando Logstash..."
            helm install logstash elastic/logstash \
              --namespace logging \
              --set logstashPipeline.enabled=true \
              --set logstashPipeline.existingConfigMap=logstash-config \
              --set service.type=ClusterIP \
              --wait
          displayName: 'Instalar Logstash'

        - script: |
            echo " Verificaci贸n:"
            kubectl get all -n logging
            echo "Para acceder a Kibana, haz port-forward:"
            echo "kubectl port-forward svc/kibana-kibana 5601:5601 -n logging"
          displayName: 'Verificaci贸n Post-Instalaci贸n'

